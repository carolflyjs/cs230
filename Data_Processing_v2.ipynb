{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Processing_v2.ipynb",
      "provenance": [],
      "mount_file_id": "1z0FybKzkPPz_-41hIlc4otEOL3E1F6Oi",
      "authorship_tag": "ABX9TyPbCun+IrEochhq1tu1luWr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolflyjs/cs230/blob/master/Data_Processing_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fnmjCAWx3D-",
        "colab_type": "code",
        "outputId": "b6ccefb5-fd81-4d1a-cead-774e9d599c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install pyspellchecker "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FReb7X4WxPaF",
        "colab_type": "code",
        "outputId": "a86d96cb-f3a6-4844-dc88-8fda3b55e022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, concatenate, Dot, Embedding, LSTM\n",
        "from keras.engine import Layer\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing import sequence\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d94d7417f270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WDtWGMhxuB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_file(path, delimiter=\",\"):\n",
        "    df = pd.read_csv(path, delimiter=delimiter)\n",
        "    df = shuffle(df).reset_index(drop=True)\n",
        "    class_dict = {\n",
        "      \"BT\": 0,\n",
        "      \"NT\": 1,\n",
        "      \"NPT\": 2,\n",
        "      \"PT\": 2,\n",
        "      \"RT\": 3,\n",
        "      \"URT\": 3\n",
        "    }\n",
        "    df[\"label\"] = df[\"label\"].apply(lambda x: class_dict[x])\n",
        "    return df\n",
        "\n",
        "def data_prep(df, x_columns, y_columns):\n",
        "    X_train = df[x_columns]\n",
        "    Y_train = df[y_columns]\n",
        "    Y_train = keras.utils.to_categorical(Y_train, num_classes=4)\n",
        "    return X_train, Y_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV1VUJ_D0E5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def removeSpellingErrors(df):\n",
        "    new_list = []\n",
        "    spell = SpellChecker()\n",
        "    raw_df_list = df.values.tolist()\n",
        "\n",
        "    for (source, target, label) in raw_df_list:\n",
        "        if len(spell.unknown(source.split())) == 0 and len(spell.unknown(target.split())) == 0:\n",
        "            new_list.append((source, target, label))\n",
        "    new_df = pd.DataFrame(new_list, columns=[\"source\", \"target\", \"label\"])\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R5RE65105BC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_pad(X_train):\n",
        "    def tokenize(X_train):\n",
        "        t = text.Tokenizer()\n",
        "        fit_text = pd.concat([X_train[\"source\"], X_train[\"target\"]])\n",
        "        t.fit_on_texts(fit_text)\n",
        "        X_train_transformed = X_train.copy()\n",
        "        X_train_transformed[\"source\"] = t.texts_to_sequences(X_train[\"source\"])\n",
        "        X_train_transformed[\"target\"] = t.texts_to_sequences(X_train[\"target\"])\n",
        "        max_value = 0\n",
        "        for series in [\"source\", \"target\"]:\n",
        "            current_max = (df[series].apply(lambda ls: len(ls))).max()\n",
        "            if current_max > max_value:\n",
        "                max_value = current_max\n",
        "        max_value = max_value\n",
        "        vocab_size = len(t.index_word) + 1\n",
        "        return X_train_transformed,  max_value, vocab_size, t\n",
        "    def pad(X, max_value):\n",
        "        source = sequence.pad_sequences(X[\"source\"],  maxlen=max_value)\n",
        "        target = sequence.pad_sequences(X[\"target\"],  maxlen=max_value)\n",
        "        return pd.DataFrame(data=np.concatenate((source, target), axis=1))\n",
        "    X_train_tokenized, max_value, vocab_size, tokenizer = tokenize(X_train)\n",
        "    X_train_padded = pad(X_train_tokenized, max_value=max_value)\n",
        "    return X_train_padded, max_value, vocab_size, tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xghoorp05nC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_df = load_file(\"/content/drive/My Drive/cs230/train.csv\")\n",
        "df = removeSpellingErrors(raw_df)\n",
        "X_train_raw, Y_train = data_prep(df, [\"source\", \"target\"], [\"label\"])\n",
        "X_train_tokenized, max_value, vocab_size, tokenizer = tokenize_and_pad(X_train_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mGn9TV508pd",
        "colab_type": "code",
        "outputId": "e26ed438-2653-4967-e51f-e29265685fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.groupby(\"label\").count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2727</td>\n",
              "      <td>2727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2638</td>\n",
              "      <td>2638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11643</td>\n",
              "      <td>11643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5880</td>\n",
              "      <td>5880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       source  target\n",
              "label                \n",
              "0        2727    2727\n",
              "1        2638    2638\n",
              "2       11643   11643\n",
              "3        5880    5880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3NaLEEW1g4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weight = {0: 6, 1: 6, 2: 1, 3: 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIHvfnL21nIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}