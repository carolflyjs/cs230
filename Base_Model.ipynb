{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Base_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPn6UEo8XIJSxVtoi45BKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolflyjs/cs230/blob/master/Base_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDa0KyhLq90E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, concatenate, Dot, Embedding\n",
        "from keras.engine import Layer\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kc8HJQprLyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_file(path, delimiter=\",\"):\n",
        "    df = pd.read_csv(path, delimiter=delimiter)\n",
        "    class_dict = {\n",
        "      \"BT\": 0,\n",
        "      \"NT\": 1,\n",
        "      \"NPT\": 2,\n",
        "      \"PT\": 2,\n",
        "      \"RT\": 3,\n",
        "      \"URT\": 3\n",
        "    }\n",
        "    df[\"label\"] = df[\"label\"].apply(lambda x: class_dict[x])\n",
        "    return df\n",
        "\n",
        "def data_prep(df, x_columns, y_columns, train_percent = 0.8):\n",
        "    msk = np.random.rand(len(df)) < train_percent\n",
        "    df_train = df[msk]\n",
        "    df_test = df[~msk]\n",
        "    X_train = df_train[x_columns]\n",
        "    Y_train = df_train[y_columns]\n",
        "    X_test = df_test[x_columns]\n",
        "    Y_test = df_test[y_columns]\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEEGX58lsb3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = load_file(\"./train.csv\")\n",
        "X_train_raw, Y_train, X_test_raw, Y_test = data_prep(df, [\"source\", \"target\"], [\"label\"])\n",
        "Y_train_labels = keras.utils.to_categorical(Y_train, num_classes=4)\n",
        "Y_test_labels = keras.utils.to_categorical(Y_test, num_classes=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AreCA16vxvIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1c194ce9-1742-4312-968b-882489b4f073"
      },
      "source": [
        "display(df.groupby(df[\"label\"]).count())"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10010</td>\n",
              "      <td>10010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10008</td>\n",
              "      <td>10008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19982</td>\n",
              "      <td>19982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20207</td>\n",
              "      <td>20207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       source  target\n",
              "label                \n",
              "0       10010   10010\n",
              "1       10008   10008\n",
              "2       19982   19982\n",
              "3       20207   20207"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "48238"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-NzRdTvZ7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57158a87-00ef-42ad-f292-19e3b793586f"
      },
      "source": [
        "\n",
        "print(\"length of training =\", len(X_train_raw))\n",
        "print(\"length of testing =\", len(X_test_raw))"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of training = 48061\n",
            "length of testing = 12146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UToMut29OQBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(X_train, X_test):\n",
        "    t = Tokenizer()\n",
        "    fit_text = pd.concat([X_train[\"source\"], X_train[\"target\"], X_test[\"source\"], X_test[\"target\"]])\n",
        "    t.fit_on_texts(fit_text)\n",
        "    # test_text = \"The earth is an great place live\"\n",
        "    test_text = X_train[\"source\"]\n",
        "    X_train_transformed, X_test_transformed = X_train.copy(), X_test.copy()\n",
        "    X_train_transformed[\"source\"] = t.texts_to_sequences(X_train[\"source\"])\n",
        "    X_train_transformed[\"target\"] = t.texts_to_sequences(X_train[\"target\"])\n",
        "    X_test_transformed[\"source\"] = t.texts_to_sequences(X_test[\"source\"])\n",
        "    X_test_transformed[\"target\"] = t.texts_to_sequences(X_test[\"target\"])\n",
        "    max_length = 0\n",
        "    for df in [X_train_transformed, X_test_transformed]:\n",
        "        for series in [\"source\", \"target\"]:\n",
        "            current_max = (df[series].apply(lambda ls: len(ls))).max()\n",
        "            if current_max > max_length:\n",
        "                max_length = current_max\n",
        "    max_length = max_length\n",
        "    vocab_size = len(t.index_word) + 1\n",
        "    return X_train_transformed, X_test_transformed, max_length, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBFyu6nhRA_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tokenized, X_test_tokenized, max_value, vocab_size = tokenize(X_train_raw, X_test_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FfjnTCoomK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(X, max_value):\n",
        "    source = sequence.pad_sequences(X[\"source\"],  maxlen=max_value)\n",
        "    target = sequence.pad_sequences(X[\"target\"],  maxlen=max_value)\n",
        "    return pd.DataFrame(data=np.concatenate((source, target), axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3IsI911pxqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_padded = pad(X_train_tokenized, max_value=max_value)\n",
        "X_test_padded = pad(X_test_tokenized, max_value=max_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBf6IiiR1u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_naive_embedding_model(): \n",
        "    X_input = Input(shape=(20,), dtype=\"int32\")\n",
        "    X = Embedding(vocab_size, 10)(X_input)\n",
        "    X = keras.layers.Flatten(\"channels_last\")(X)\n",
        "    # target_input = Input(shape=(1,), dtype=\"string\")\n",
        "    # target_embed = ElmoEmbeddingLayer()(target_input)\n",
        "    # embedding = Dot(axes=1)([source_embed, target_embed])\n",
        "    # pred = Dense(4, activation='softmax')(embedding)\n",
        "    X = Dense(4, activation=\"softmax\")(X)\n",
        "\n",
        "    # model = Model(inputs=[source_input, target_input], outputs=pred)\n",
        "    model = Model(inputs=[X_input], outputs=X)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-B3Us1djaq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "2bdb5f98-e71e-47d2-ae7c-f11d9588a5e9"
      },
      "source": [
        "model = build_naive_embedding_model()\n",
        "history = model.fit([X_train_padded], Y_train_labels, epochs=20, batch_size=32, shuffle=True) "
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_25 (Embedding)     (None, 20, 10)            112120    \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4)                 804       \n",
            "=================================================================\n",
            "Total params: 112,924\n",
            "Trainable params: 112,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "48061/48061 [==============================] - 6s 120us/step - loss: 0.8888 - acc: 0.6348\n",
            "Epoch 2/20\n",
            "48061/48061 [==============================] - 5s 107us/step - loss: 0.5640 - acc: 0.7844\n",
            "Epoch 3/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.4606 - acc: 0.8258\n",
            "Epoch 4/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.4078 - acc: 0.8456\n",
            "Epoch 5/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.3733 - acc: 0.8580\n",
            "Epoch 6/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.3472 - acc: 0.8675\n",
            "Epoch 7/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.3268 - acc: 0.8765\n",
            "Epoch 8/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.3094 - acc: 0.8831\n",
            "Epoch 9/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.2950 - acc: 0.8879\n",
            "Epoch 10/20\n",
            "48061/48061 [==============================] - 5s 102us/step - loss: 0.2824 - acc: 0.8930\n",
            "Epoch 11/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.2710 - acc: 0.8975\n",
            "Epoch 12/20\n",
            "48061/48061 [==============================] - 5s 109us/step - loss: 0.2620 - acc: 0.9001\n",
            "Epoch 13/20\n",
            "48061/48061 [==============================] - 5s 102us/step - loss: 0.2536 - acc: 0.9036\n",
            "Epoch 14/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.2463 - acc: 0.9073\n",
            "Epoch 15/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.2400 - acc: 0.9092\n",
            "Epoch 16/20\n",
            "48061/48061 [==============================] - 5s 107us/step - loss: 0.2347 - acc: 0.9109\n",
            "Epoch 17/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.2302 - acc: 0.9133\n",
            "Epoch 18/20\n",
            "48061/48061 [==============================] - 5s 105us/step - loss: 0.2259 - acc: 0.9153\n",
            "Epoch 19/20\n",
            "48061/48061 [==============================] - 5s 104us/step - loss: 0.2222 - acc: 0.9157\n",
            "Epoch 20/20\n",
            "48061/48061 [==============================] - 6s 117us/step - loss: 0.2189 - acc: 0.9176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac54643668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIWHjmh2ufDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a7827e9-f335-4988-ae4c-6c51583d10cf"
      },
      "source": [
        "model.evaluate(X_test_padded, Y_test_labels, verbose=0)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8912734743661622, 0.7602502881508967]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4lkc--r41OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}